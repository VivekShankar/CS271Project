{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f6679d6-6c9e-47e3-81c4-e2be05e54e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import timm\n",
    "import torch\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    ShiftScaleRotate,\n",
    "    RandomBrightnessContrast,\n",
    "    MotionBlur,\n",
    "    CLAHE,\n",
    "    HorizontalFlip\n",
    ")\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199e82ef-b899-425f-b8db-456666bd1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"vinbigdata-chest-xray-resized-png-256x256\"\n",
    "processed_path = \"VinBigData-Chest-X-ray-Abnormalities-Detection/vinbigdata_classifierPP_2021\"\n",
    "\n",
    "csv_path = os.path.join(processed_path, 'input/vinbigdata-chest-xray-abnormalities-detection/multilabel_cls_train.csv')\n",
    "pos_weight_path = os.path.join(processed_path, 'input/vinbigdata-chest-xray-abnormalities-detection/multilabel_pos_weight.npy')\n",
    "image_path = os.path.join(dataset_path, 'train') # The path to the folder with converted PNG files\n",
    "save_path = os.path.join(processed_path, 'classifier_weights/1024/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a5f885-59dc-428a-83d6-220cd02567c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, image_path, transform=None):\n",
    "        self.df = df\n",
    "        self.image_path = image_path\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        labels = torch.from_numpy(\n",
    "            self.df.loc[idx,np.arange(0,15).astype(str).tolist()].values.astype(float)\n",
    "        ).float()\n",
    "\n",
    "        img = cv2.imread(\n",
    "            self.image_path + '/' + str(self.df.image_id[idx]) + '.png'\n",
    "        )\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        img = torch.from_numpy(img.transpose((2, 0, 1))).float()\n",
    "            \n",
    "        return img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c975a47e-9cd3-4bf1-b8de-2fe6249e1c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vinbigdata-chest-xray-resized-png-256x256/test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>rad_id</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50a418190bc3fb1ef1633bf9678929b3</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2332</td>\n",
       "      <td>2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21a10246a5ec7af151081d0cd6d65dc9</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2954</td>\n",
       "      <td>3159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>3</td>\n",
       "      <td>R10</td>\n",
       "      <td>691.0</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>2080</td>\n",
       "      <td>2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>051132a778e61a86eb147c7c6f564dfe</td>\n",
       "      <td>Aortic enlargement</td>\n",
       "      <td>0</td>\n",
       "      <td>R10</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>2304</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>063319de25ce7edb9b1c6b8881290140</td>\n",
       "      <td>No finding</td>\n",
       "      <td>14</td>\n",
       "      <td>R10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2540</td>\n",
       "      <td>3072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id          class_name  class_id rad_id  \\\n",
       "0  50a418190bc3fb1ef1633bf9678929b3          No finding        14    R11   \n",
       "1  21a10246a5ec7af151081d0cd6d65dc9          No finding        14     R7   \n",
       "2  9a5094b2563a1ef3ff50dc5c7ff71345        Cardiomegaly         3    R10   \n",
       "3  051132a778e61a86eb147c7c6f564dfe  Aortic enlargement         0    R10   \n",
       "4  063319de25ce7edb9b1c6b8881290140          No finding        14    R10   \n",
       "\n",
       "    x_min   y_min   x_max   y_max  width  height  \n",
       "0     NaN     NaN     NaN     NaN   2332    2580  \n",
       "1     NaN     NaN     NaN     NaN   2954    3159  \n",
       "2   691.0  1375.0  1653.0  1831.0   2080    2336  \n",
       "3  1264.0   743.0  1611.0  1019.0   2304    2880  \n",
       "4     NaN     NaN     NaN     NaN   2540    3072  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = os.path.join(dataset_path, 'test')\n",
    "print(test_path)\n",
    "df = pd.read_csv(dataset_path+\"/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64275a53-bb08-4158-9842-c2a9d851e56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>ea93703162b05a5c8acf2e18c2f69acf</td>\n",
       "      <td>2642</td>\n",
       "      <td>3170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image_id  width  height\n",
       "2885  ea93703162b05a5c8acf2e18c2f69acf   2642    3170"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path+\"/test.csv\")\n",
    "df.head()\n",
    "image = \"ea93703162b05a5c8acf2e18c2f69acf\"\n",
    "df.query(\"image_id==@image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bba6a2-97bb-4339-8f28-312e12f85997",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "lr = 1e-3\n",
    "N_EPOCHS = 100\n",
    "IMG_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e6b215-83f6-4972-9afc-04b88613d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b5a9b34-0bec-4bbb-9ffb-66a1383861f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion): # train 1 epoch\n",
    "    \"\"\"\n",
    "    Trains the model for 1 epoch\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The model to be trained.\n",
    "        train_loader (torch.utils.data.DataLoader): Dataloader object for training.\n",
    "        optimizer (A torch.optim class): The optimizer.\n",
    "        criterion (A function in torch.nn.modules.loss): The loss function. \n",
    "        \n",
    "    Return: \n",
    "        avg_loss (float): The average loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train() \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_n = 0.0\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)\n",
    "    for idx, (imgs, labels) in enumerate(tk):\n",
    "        imgs_train, labels_train = imgs.cuda(), labels.cuda()\n",
    "        output_train = model(imgs_train)\n",
    "        \n",
    "        loss = criterion(output_train, labels_train) \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_n += imgs_train.size(0)\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        tk.set_postfix(loss=running_loss / running_n)\n",
    "        \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3721fba9-8e1c-45c9-b439-e1a350297974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_model(model, val_loader, criterion):\n",
    "    \"\"\"\n",
    "    Test the model on the validation set\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The model to be trained.\n",
    "        val_loader (torch.utils.data.DataLoader): Dataloader object for validation.\n",
    "        optimizer (A torch.optim class): The optimizer.\n",
    "        criterion (A torch.nn.modules.loss class): The loss function. \n",
    "        \n",
    "    Return: \n",
    "        avg_val_loss (float): The average loss.\n",
    "        aucs (np.array): The validation AUC of each class.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_n = 0.0\n",
    "    avg_loss = 0.0\n",
    "    valid_preds, valid_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tk = tqdm(val_loader, total=len(val_loader), position=0, leave=True)\n",
    "        \n",
    "        for idx, (imgs, labels) in enumerate(tk):  \n",
    "            imgs_valid, labels_valid = imgs.cuda(), labels.cuda()\n",
    "            output_valid = model(imgs_valid)\n",
    "            \n",
    "            loss = criterion(output_valid, labels_valid)\n",
    "            running_loss += loss.item()\n",
    "            running_n += imgs_valid.size(0)\n",
    "            avg_loss += loss.item() / len(val_loader)\n",
    "            tk.set_postfix(loss=running_loss / running_n)\n",
    "            \n",
    "            valid_pred = torch.sigmoid(output_valid).detach().cpu().numpy()\n",
    "            label_valid = labels_valid.detach().cpu().numpy()\n",
    "         \n",
    "            valid_preds.append(valid_pred)\n",
    "            valid_targets.append(label_valid.round().astype(int))\n",
    "\n",
    "        valid_preds = np.concatenate(valid_preds,axis=0).T\n",
    "        valid_targets = np.concatenate(valid_targets,axis=0).T\n",
    "        \n",
    "        aucs = np.array(\n",
    "            [roc_auc_score(i,j) if len(set(i))>1 else np.nan for i,j in zip(valid_targets, valid_preds)]\n",
    "        )\n",
    "        overall_auc = np.nanmean(aucs)\n",
    "        \n",
    "    return avg_loss, aucs, overall_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd4e4f5-dc59-4d01-886e-25e9966119cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    seed_everything(42)\n",
    "\n",
    "    train = pd.read_csv(csv_path)\n",
    "\n",
    "    train_transform = Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        ShiftScaleRotate(scale_limit = 0.15, rotate_limit = 10, p = 0.5),\n",
    "        RandomBrightnessContrast(p=0.5),\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0)\n",
    "    ])\n",
    "    test_transform = Compose([\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0)\n",
    "    ])\n",
    "\n",
    "    for fold in range(5):\n",
    "        trainset = TrainDataset(\n",
    "            train.loc[train['fold']!=fold].reset_index(),\n",
    "            image_path = image_path,\n",
    "            transform=train_transform\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            trainset, batch_size=bs, num_workers=1,\n",
    "            shuffle=True \n",
    "        )\n",
    "\n",
    "        valset = TrainDataset(\n",
    "            train.loc[train['fold']==fold].reset_index(),\n",
    "            image_path = image_path,\n",
    "            transform=test_transform\n",
    "        )\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            valset, batch_size=bs, shuffle=False, num_workers=1\n",
    "        )\n",
    "\n",
    "        model = timm.create_model('tf_efficientnet_b4_ns',pretrained=True,num_classes=15).cuda()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, factor=0.1, mode='max')\n",
    "\n",
    "        best_weights = deepcopy(model.state_dict())\n",
    "        previous_lr = lr\n",
    "        best_auc = 0\n",
    "        best_aucs = [0]*15\n",
    "        best_val_loss = 100\n",
    "        es = 0\n",
    "\n",
    "        for epoch in range(N_EPOCHS):\n",
    "            avg_loss = train_model(model, train_loader, optimizer, criterion)\n",
    "            avg_val_loss, aucs, auc = val_model(model, val_loader, criterion)\n",
    "\n",
    "            print(\n",
    "                'epoch:', epoch, 'lr:', previous_lr, 'val_loss:',avg_val_loss, 'weighted avg auc:',auc\n",
    "            )\n",
    "            print('aucs:',aucs)\n",
    "\n",
    "            # Record the best weights if either of AUC or val_loss improved.\n",
    "            if auc > best_auc or avg_val_loss < best_val_loss:\n",
    "                print('saving best weight...')\n",
    "                best_weights = deepcopy(model.state_dict())\n",
    "                for k,v in best_weights.items():\n",
    "                    best_weights[k] = v.cpu()\n",
    "\n",
    "            # Save the model weight if the AUC of any class is improved. \n",
    "            for i in range(len(best_aucs)):\n",
    "                if aucs[i] > best_aucs[i]:\n",
    "                    best_aucs[i] = aucs[i]\n",
    "                    d = {\n",
    "                        'weight':model.state_dict(),\n",
    "                        'auc':aucs[i],\n",
    "                        'epoch':epoch,\n",
    "                    }\n",
    "                    torch.save(\n",
    "                        d, save_path + f'multilabel_efnb4_v1_cls{i}_fold{fold}.pth'\n",
    "                    )\n",
    "\n",
    "            # Update best avg_val_loss\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "\n",
    "            # Update best weighted../../results/multilabel_cls/v2/ AUC and implement early stop\n",
    "            if auc > best_auc:\n",
    "                es = 0\n",
    "                best_auc = auc\n",
    "            else:\n",
    "                es += 1\n",
    "                if es > 10:\n",
    "                    break\n",
    "\n",
    "            scheduler.step(auc)  \n",
    "\n",
    "            # if lr changes, start from previous best weight:\n",
    "            if optimizer.param_groups[0]['lr'] < previous_lr:\n",
    "                print('restoring best weight...')\n",
    "                model.load_state_dict(best_weights)\n",
    "                previous_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "                if optimizer.param_groups[0]['lr'] < 0.99e-6:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63527b17-3e8b-4358-9252-b43adbbc9298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed6c7a0804d4ce1a9620f7a55180718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2779/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2779/2779572397.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mavg_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maucs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2779/4115117794.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6900046-7adc-4035-9146-1a9df54b7799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
